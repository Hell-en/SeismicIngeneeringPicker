{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c63e2f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15960/306516062.py:3: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n",
      "2025-01-19 15:37:51.412274: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-19 15:37:51.506145: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-19 15:37:51.991332: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/obersht/miniconda3/envs/tf/lib/\n",
      "2025-01-19 15:37:51.992143: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/obersht/miniconda3/envs/tf/lib/\n",
      "2025-01-19 15:37:51.992150: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pylab as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import segyio as sio\n",
    "from src import segyrw\n",
    "from src import dsp\n",
    "import ipywidgets as ipw\n",
    "import tensorflow as tf\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f088d48-d088-43d4-88f0-567de33f214a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import CNNCreator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "049491be-03fb-47b4-9c9f-8577c5632082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7fd890226df0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CNNCreator.model_conv1d(\n",
    "    3,\n",
    "    shape=1000,\n",
    "    depth=4,\n",
    "    filters=32,\n",
    "    kernel_size=32,\n",
    "    channels=1,\n",
    "    activation='relu',\n",
    "    last_activation='softmax',\n",
    "    last_kernel_size=32,\n",
    "    dropout=.5,\n",
    "    batch_norm=True,\n",
    "    acivation_after_batch=False,\n",
    "    pooling=None,\n",
    "    lr=0.001,)\n",
    "model.load_weights('../fb_picking_notebooks/models/model_weights_mount')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d63eece5-bae5-40c0-a68d-649ffb1544db",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"../FBdata/npy/with_picks/Kluchi2014.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "83f50ccc-f256-463f-8e5e-3a8451565620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 12ms/step\n"
     ]
    }
   ],
   "source": [
    "result = model.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2e432796-d647-4c47-b5b7-41d6df248095",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(808, 1000, 3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "42714150-e519-42e7-a148-c752f8d1763e",
   "metadata": {},
   "outputs": [],
   "source": [
    "picks = np.argmax(result[:,:,1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "34ee6e19-7691-4df8-8667-45691f7cef2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946,\n",
       "       946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946,\n",
       "       946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946,\n",
       "       946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946,\n",
       "       946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946,\n",
       "       946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946,\n",
       "       946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946,\n",
       "       946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946,\n",
       "       946, 946, 946,  55, 946, 946, 946,  45,  74,  80, 946, 946, 946,\n",
       "       946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946,\n",
       "       946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946,\n",
       "       946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946,\n",
       "       946, 946, 946, 946, 946, 946, 946,  57, 946, 946, 946, 946, 946,\n",
       "       946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946,\n",
       "       946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946,\n",
       "       946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946,\n",
       "       946, 946, 946, 946, 946,  55, 946,  56, 946, 946, 946, 946, 946,\n",
       "       946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946,\n",
       "       946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946,\n",
       "       946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946,\n",
       "       946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946,\n",
       "       946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946,\n",
       "       946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946,\n",
       "       946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946,\n",
       "       946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946,\n",
       "       946, 946, 946, 946,  83, 946, 946, 946, 946, 946, 946, 946, 946,\n",
       "       946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946,\n",
       "       946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946,\n",
       "       946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946,\n",
       "       946, 946, 946, 946, 946, 946,  75, 946, 946, 946, 946, 946, 946,\n",
       "       946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946,\n",
       "       946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946,\n",
       "       946, 946, 946, 946, 946, 946,  54, 946, 946, 946, 946, 946, 946,\n",
       "       946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946,\n",
       "       946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946,\n",
       "       946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946,\n",
       "       946, 946, 946, 946, 946, 946, 946,  86, 946, 946, 946, 946, 946,\n",
       "       946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946,\n",
       "       946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946,\n",
       "       946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946,\n",
       "       946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946,\n",
       "       946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946,\n",
       "       946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946,\n",
       "       946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946,\n",
       "       946, 946, 946,  62,  57, 946, 946, 946, 946, 946, 946, 946, 946,\n",
       "       946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946,\n",
       "       946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946,\n",
       "       946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946,\n",
       "       946, 946, 946, 946, 946, 946, 946, 946, 946, 946,  58, 946, 946,\n",
       "       946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946,\n",
       "       946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946,\n",
       "       946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946,\n",
       "       946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946,\n",
       "       946, 946, 946, 946,  58, 946, 946, 947, 946, 946, 946, 946, 946,\n",
       "       946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946,\n",
       "       946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946,\n",
       "       946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946,\n",
       "       946, 946, 946, 946, 946, 946,  65,  54, 946, 946,  52, 946, 132,\n",
       "       946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946,\n",
       "       946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946,\n",
       "       946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946, 946,\n",
       "       946, 946, 946, 946, 946, 946,  52,  76, 104, 946, 946, 946, 946,\n",
       "       946, 946])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "picks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8852523c-9947-4064-ad0f-9a23fa4a5cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_picks = np.load(\"../FBdata/npy/with_picks/Kluchi2014_picks.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cd3c78dd-9757-45d3-9ecc-1c307680792a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,  37,  61,  82,  92, 115, 136, 147, 151, 153, 156, 161, 165,\n",
       "       163, 159, 156, 158, 156, 157, 155, 155, 155, 154, 150, 148, 151,\n",
       "       149, 148, 147, 146, 147, 149,  36,   0,  31,  62,  75,  80,  90,\n",
       "       100, 116, 121, 138, 141, 155, 157, 156, 156, 151, 150, 151, 148,\n",
       "       148, 150, 147, 146, 147, 145, 145, 142, 141, 140, 138, 140, 142,\n",
       "       141, 138, 139, 141, 139, 141,  67,  61,  32,   0,  33,  51, 106,\n",
       "       126, 146, 148, 146, 146, 146, 144, 142, 139, 138, 140, 136, 136,\n",
       "       135, 136, 135, 134,  96,  92,  85,  80,  74,  68,  62,  56,  50,\n",
       "        43,  38,  32,  27,  21,   0,  19,  26,  33,  38,  43,  48,  54,\n",
       "        59,  75,  97, 120, 125, 131, 130, 131, 131, 130, 129, 129, 131,\n",
       "       128, 126, 128, 125, 124, 124, 125, 124, 123, 123, 123, 123, 125,\n",
       "       123, 126, 128, 126, 127, 125, 125, 120, 115, 107,  97,  90,  88,\n",
       "        76,  67,  58,  44,  39,  33,   0,  31,  54,  60,  65,  82,  87,\n",
       "       103, 106, 110, 115, 120, 122, 123, 122, 121, 121, 123, 120, 120,\n",
       "       120, 120, 121, 120, 121, 119, 116, 117, 116, 116, 119, 118, 118,\n",
       "       120, 120, 139, 136, 132, 129, 122, 116, 111, 104, 100,  94,  72,\n",
       "        64,  59,  50,  44,  38,  31,  25,  19,  13,   0,  31,  56,  61,\n",
       "        82,  86,  92,  97, 103, 106, 109, 113, 117, 115, 116, 116, 117,\n",
       "       114, 114, 114, 112, 112, 111, 112, 111, 112, 111, 112, 111, 114,\n",
       "       112, 112, 114, 115, 115, 160, 153, 156, 146, 143, 138, 136, 128,\n",
       "       119, 113,  96,  90,  83,  79,  74,  70,  66,  60,  31,   0,  32,\n",
       "        45,  52,  62,  67,  75,  82,  85,  98, 102, 106, 107, 106, 108,\n",
       "       107, 106, 105, 106, 104, 103, 102, 104, 104, 102, 105, 103, 103,\n",
       "       108, 110, 111, 165, 165, 163, 162, 159, 154, 152, 146, 143, 136,\n",
       "       127, 116, 109, 104, 100,  94,  91,  86,  82,  77,  74,  70,  65,\n",
       "        61,  48,  30,   0,  33,  40,  52,  57,  75,  79,  84,  87,  93,\n",
       "        96,  97,  99,  97,  96,  95,  98,  94,  94,  94,  94,  95,  96,\n",
       "        95,  98,  99, 100, 100, 161, 160, 160, 159, 156, 156, 150, 145,\n",
       "       140, 136, 130, 125, 121, 117, 114, 106,  95,  86,  81,  71,  65,\n",
       "        59,  54,  48,  42,  33,   0,  33,  43,  59,  63,  79,  83,  86,\n",
       "        85,  84,  84,  85,  83,  84,  83,  83,  83,  84,  85,  85,  86,\n",
       "        88,  88,  90,  90,  92, 114, 111, 103,  97,  92,  81,  76,  70,\n",
       "        58,  53,  47,  38,  33,   0,  30,  44,  49,  53,  57,  61,  67,\n",
       "        71,  72,  70,  71,  71,  70,  72,  72,  70,  72,  71,  71,  70,\n",
       "        69,  70,  72,  71,  71,  71,  72,  71,  72,  72,  75,  75,  76,\n",
       "        76,  79, 113, 110, 106, 102,  97,  91,  86,  82,  79,  74,  71,\n",
       "        67,  63,  59,  55,  49,  30,   0,  31,  57,  60,  60,  61,  61,\n",
       "        62,  63,  61,  63,  62,  61,  61,  60,  59,  62,  62,  62,  62,\n",
       "        62,  64,  62,  62,  62,  67,  66,  68,  68, 114, 111, 106, 102,\n",
       "        99,  96,  93,  90,  88,  84,  80,  78,  71,  66,  61,  57,  53,\n",
       "        31,   0,  49,  53,  53,  53,  54,  53,  54,  54,  55,  52,  52,\n",
       "        54,  54,  53,  53,  52,  56,  55,  56,  54,  57,  59,  58,  61,\n",
       "        60,  60,  61, 117, 114, 115, 110, 107, 106, 103, 100,  98,  96,\n",
       "        94,  90,  88,  85,  81,  78,  75,  72,  70,  68,  66,  63,  60,\n",
       "        56,  49,  43,  37,  32,  25,   0,  17,  32,  36,  42,  45,  46,\n",
       "        44,  44,  45,  44,  43,  45,  45,  44,  45,  46,  46,  45,  45,\n",
       "        48,  51,  51,  53,  53,  54,  54, 107, 105, 103, 101,  96,  95,\n",
       "        91,  89,  88,  86,  84,  78,  76,  73,  70,  69,  67,  65,  64,\n",
       "        62,  60,  58,  56,  55,  53,  51,  50,  44,  38,  32,  26,  20,\n",
       "         0,  16,  23,  30,  34,  35,  34,  33,  35,  35,  34,  34,  34,\n",
       "        37,  35,  36,  36,  40,  41,  40,  43,  42,  43,  44, 107, 104,\n",
       "       100,  98,  96,  94,  91,  89,  87,  85,  83,  79,  76,  73,  71,\n",
       "        68,  66,  66,  63,  62,  59,  57,  55,  54,  52,  51,  51,  47,\n",
       "        44,  41,  40,  39,  36,  31,  26,   0,  18,  23,  24,  25,  25,\n",
       "        25,  25,  28,  27,  28,  27,  33,  32,  35,  34,  34,  91,  89,\n",
       "        88,  86,  83,  78,  76,  73,  70,  69,  68,  66,  63,  62,  59,\n",
       "        58,  56,  56,  54,  52,  51,  50,  46,  44,  42,  41,  40,  38,\n",
       "        35,  35,  33,  28,  27,  24,  22,  18,   0,  13,  15,  15,  18,\n",
       "        16,  17,  18,  21,  23,  23,  25,  25,  25,  27,  70,  69,  68,\n",
       "        66,  64,  63,  60,  58,  56,  54,  53,  52,  48,  46,  44,  43,\n",
       "        42,  40,  37,  38,  36,  32,  31,  28,  26,  24,  21,  19,  18,\n",
       "        16,  13,  12,   8,   0,   7,   8,   9,  11,  14,  14,  17,  16,\n",
       "        17,  19], dtype=int32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_picks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "82c7b757-2290-4905-951b-8dd109a18c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_picks = abs(picks - true_picks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fe38839d-0704-427f-8015-699e9ce57391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([946, 909, 885, 864, 854, 831, 810, 799, 795, 793, 790, 785, 781,\n",
       "       783, 787, 790, 788, 790, 789, 791, 791, 791, 792, 796, 798, 795,\n",
       "       797, 798, 799, 800, 799, 797, 910, 946, 915, 884, 871, 866, 856,\n",
       "       846, 830, 825, 808, 805, 791, 789, 790, 790, 795, 796, 795, 798,\n",
       "       798, 796, 799, 800, 799, 801, 801, 804, 805, 806, 808, 806, 804,\n",
       "       805, 808, 807, 805, 807, 805, 879, 885, 914, 946, 913, 895, 840,\n",
       "       820, 800, 798, 800, 800, 800, 802, 804, 807, 808, 806, 810, 810,\n",
       "       811, 810, 811, 812, 850, 854, 861, 866, 872, 878, 884, 890, 896,\n",
       "       903, 908, 914,  28, 925, 946, 927,  19,  41,  42, 903, 898, 892,\n",
       "       887, 871, 849, 826, 821, 815, 816, 815, 815, 816, 817, 817, 815,\n",
       "       818, 820, 818, 821, 822, 822, 821, 822, 823, 823, 823, 823, 821,\n",
       "       823, 820, 818, 820, 819, 821, 821, 826, 831, 839, 849, 856, 858,\n",
       "       870, 879, 888, 902, 907, 913, 946,  26, 892, 886, 881, 864, 859,\n",
       "       843, 840, 836, 831, 826, 824, 823, 824, 825, 825, 823, 826, 826,\n",
       "       826, 826, 825, 826, 825, 827, 830, 829, 830, 830, 827, 828, 828,\n",
       "       826, 826, 807, 810, 814, 817, 824, 830, 835, 842, 846, 852, 874,\n",
       "       882, 887, 896, 902, 908,  24, 921,  37, 933, 946, 915, 890, 885,\n",
       "       864, 860, 854, 849, 843, 840, 837, 833, 829, 831, 830, 830, 829,\n",
       "       832, 832, 832, 834, 834, 835, 834, 835, 834, 835, 834, 835, 832,\n",
       "       834, 834, 832, 831, 831, 786, 793, 790, 800, 803, 808, 810, 818,\n",
       "       827, 833, 850, 856, 863, 867, 872, 876, 880, 886, 915, 946, 914,\n",
       "       901, 894, 884, 879, 871, 864, 861, 848, 844, 840, 839, 840, 838,\n",
       "       839, 840, 841, 840, 842, 843, 844, 842, 842, 844, 841, 843, 843,\n",
       "       838, 836, 835, 781, 781, 783, 784, 787, 792, 794, 800, 803, 810,\n",
       "       819, 830, 837, 842, 846, 852, 855, 860, 864, 869, 872, 876, 881,\n",
       "       885, 898, 916, 946,  50, 906, 894, 889, 871, 867, 862, 859, 853,\n",
       "       850, 849, 847, 849, 850, 851, 848, 852, 852, 852, 852, 851, 850,\n",
       "       851, 848, 847, 846, 846, 785, 786, 786, 787, 790, 790, 796, 801,\n",
       "       806, 810, 816, 821, 825, 829, 832, 840, 851, 860, 865, 875, 881,\n",
       "       887, 892, 898, 904, 913, 946,  42, 903, 887, 883, 867, 863, 860,\n",
       "       861, 862, 862, 861, 863, 862, 863, 863, 863, 862, 861, 861, 860,\n",
       "       858, 858, 856, 856, 854, 832, 835, 843, 849, 854, 865, 870, 876,\n",
       "       888, 893, 899, 908, 913, 946,  24, 902, 897, 893, 889, 885, 879,\n",
       "       875, 874, 876, 875, 875, 876, 874, 874, 876, 874, 875, 875, 876,\n",
       "       877, 876, 874, 875, 875, 875, 874, 875, 874, 874, 871, 871, 870,\n",
       "       870, 867, 833, 836, 840, 844, 849, 855, 860, 864, 867, 872, 875,\n",
       "       879, 883, 887, 891, 897, 916, 946,  55, 889, 886, 886, 885, 885,\n",
       "       884, 883, 885, 883, 884, 885, 885, 886, 887, 884, 884, 884, 884,\n",
       "       884, 882, 884, 884, 884, 879, 880, 878, 878, 832, 835, 840, 844,\n",
       "       847, 850, 853, 856, 858, 862, 866, 868, 875, 880, 885, 889, 893,\n",
       "       915, 946, 897, 893, 893, 893, 892, 893, 892, 892, 891, 894, 894,\n",
       "       892, 892, 893, 893, 894, 890, 891, 890, 892, 889, 887, 888, 885,\n",
       "       886, 886, 885, 829, 832, 831, 836, 839, 840, 843, 846, 848, 850,\n",
       "       852, 856, 858, 861, 865, 868, 871, 874, 876, 878, 880, 883, 886,\n",
       "       890, 897, 903,  25,  25, 921, 946, 929, 914, 910, 904, 901, 900,\n",
       "       902, 902, 901, 902, 903, 901, 901, 902, 901, 900, 900, 901, 901,\n",
       "       898, 895, 895, 893, 893, 892, 892, 839, 841, 843, 845, 850, 851,\n",
       "       855, 857, 858, 860, 862, 868, 870, 873, 876, 877, 879, 881, 882,\n",
       "       884, 886, 888, 890, 891, 893, 895, 896, 902, 908,  26, 920, 926,\n",
       "       946, 930, 923, 916, 912, 911, 912, 913, 911, 911, 912, 912, 912,\n",
       "       909, 911, 910, 910, 906, 905, 906, 903, 904, 903, 902, 839, 842,\n",
       "       846, 848, 850, 852, 855, 857, 859, 861, 863, 867, 870, 873, 875,\n",
       "       878, 880, 880, 883, 884, 887, 889, 891, 892, 894, 895, 895, 899,\n",
       "       902, 905, 906, 907,  22, 915, 920, 947, 928, 923, 922, 921, 921,\n",
       "       921, 921, 918, 919, 918, 919, 913, 914, 911, 912, 912, 855, 857,\n",
       "       858, 860, 863, 868, 870, 873, 876, 877, 878, 880, 883, 884, 887,\n",
       "       888, 890, 890, 892, 894, 895, 896, 900, 902, 904, 905, 906, 908,\n",
       "       911, 911, 913, 918, 919, 922,  43,  36, 946, 933,  37, 931, 114,\n",
       "       930, 929, 928, 925, 923, 923, 921, 921, 921, 919, 876, 877, 878,\n",
       "       880, 882, 883, 886, 888, 890, 892, 893, 894, 898, 900, 902, 903,\n",
       "       904, 906, 909, 908, 910, 914, 915, 918, 920, 922, 925, 927, 928,\n",
       "       930, 933, 934, 938, 946, 939,  44,  67,  93, 932, 932, 929, 930,\n",
       "       929, 927])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff_picks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59d8d07-d76a-44a7-b858-9d31a841c13b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
